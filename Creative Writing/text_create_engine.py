"""
Tree of Thought (ToT) implementation for creative writing
Based on the Princeton NLP Tree-of-Thought-LLM paper
Using OpenAI 0.29.0 library with DeepSeek model
"""

import openai
import asyncio
import json
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import os
from dotenv import load_dotenv

load_dotenv()

class ThoughtState:
    """Represents a state in the thought tree"""
    def __init__(self, content: str, depth: int, parent=None, score: float = 0.0):
        self.content = content
        self.depth = depth
        self.parent = parent
        self.children = []
        self.score = score
        self.is_evaluated = False
    
    def add_child(self, child):
        child.parent = self
        self.children.append(child)
        return child

class TreeOfThought:
    """Tree of Thought implementation for creative writing"""
    
    def __init__(self, api_key: str, base_url: str = None):
        openai.api_key = api_key
        if base_url:
            openai.api_base = base_url
        self.max_depth = 3
        self.num_thoughts_per_step = 3
        self.num_evaluations = 5
    
    def generate_thoughts(self, prompt: str, current_state: str = "", depth: int = 0) -> List[str]:
        """Generate multiple thought continuations from current state"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œä¸“å®¶ã€‚åŸºäºç»™å®šçš„æç¤ºå’Œå½“å‰å†…å®¹ï¼Œç”Ÿæˆå¤šä¸ªä¸åŒçš„åˆ›æ„ç»­å†™æ–¹å‘ã€‚
æ¯ä¸ªæ–¹å‘åº”è¯¥ï¼š
1. å…·æœ‰ç‹¬ç‰¹çš„åˆ›æ„è§’åº¦
2. ä¿æŒé€»è¾‘è¿è´¯æ€§
3. å±•ç°ä¸°å¯Œçš„æƒ³è±¡åŠ›
4. é€‚åˆè¿›ä¸€æ­¥å‘å±•

è¯·ç”Ÿæˆ3ä¸ªä¸åŒçš„ç»­å†™æ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘ç”¨"---"åˆ†éš”ã€‚"""
        
        user_prompt = f"""
åŸå§‹æç¤ºï¼š{prompt}
å½“å‰å†…å®¹ï¼š{current_state}
æ·±åº¦ï¼š{depth}

è¯·ä¸ºè¿™ä¸ªåˆ›æ„å†™ä½œä»»åŠ¡ç”Ÿæˆ3ä¸ªä¸åŒçš„ç»­å†™æ–¹å‘ã€‚
"""
        
        try:
            response = openai.ChatCompletion.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.8,
                max_tokens=800
            )
            
            content = response.choices[0].message.content
            thoughts = [thought.strip() for thought in content.split("---") if thought.strip()]
            
            # Ensure we have exactly the number of thoughts we want
            while len(thoughts) < self.num_thoughts_per_step:
                thoughts.append(f"ç»­å†™æ–¹å‘ {len(thoughts) + 1}: ç»§ç»­å‘å±•å½“å‰æƒ…èŠ‚...")
            
            return thoughts[:self.num_thoughts_per_step]
            
        except Exception as e:
            print(f"ç”Ÿæˆæ€è·¯æ—¶å‡ºé”™: {e}")
            return [f"é»˜è®¤ç»­å†™æ–¹å‘ {i+1}" for i in range(self.num_thoughts_per_step)]
    
    def evaluate_thought(self, prompt: str, thought: str) -> float:
        """Evaluate a single thought's quality and potential"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ›æ„å†™ä½œè¯„ä¼°ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ç»™å®šçš„åˆ›æ„å†™ä½œç‰‡æ®µï¼š
1. åˆ›æ„æ€§ (0-1åˆ†)
2. é€»è¾‘è¿è´¯æ€§ (0-1åˆ†)  
3. æ–‡å­¦ä»·å€¼ (0-1åˆ†)
4. å‘å±•æ½œåŠ› (0-1åˆ†)
5. æƒ…æ„Ÿå…±é¸£ (0-1åˆ†)

è¯·ç»™å‡º0-5åˆ†çš„æ€»åˆ†ï¼Œå¹¶ç®€è¦è¯´æ˜è¯„åˆ†ç†ç”±ã€‚
æ ¼å¼ï¼šåˆ†æ•°: X.X
ç†ç”±: [ç®€è¦è¯´æ˜]"""
        
        user_prompt = f"""
åŸå§‹æç¤ºï¼š{prompt}
å¾…è¯„ä¼°å†…å®¹ï¼š{thought}

è¯·è¯„ä¼°è¿™ä¸ªåˆ›æ„å†™ä½œç‰‡æ®µçš„è´¨é‡ã€‚
"""
        
        try:
            response = openai.ChatCompletion.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            content = response.choices[0].message.content
            
            # Extract score from response
            lines = content.split('\n')
            score = 3.0  # default score
            
            for line in lines:
                if 'åˆ†æ•°:' in line or 'Score:' in line or 'å¾—åˆ†:' in line:
                    try:
                        score_str = line.split(':')[1].strip()
                        score = float(score_str)
                        break
                    except:
                        continue
            
            return max(0.0, min(5.0, score))
            
        except Exception as e:
            print(f"è¯„ä¼°æ€è·¯æ—¶å‡ºé”™: {e}")
            return 3.0
    
    def select_best_thoughts(self, thoughts: List[ThoughtState], k: int = 2) -> List[ThoughtState]:
        """Select top k thoughts based on evaluation scores"""
        evaluated_thoughts = []
        
        for thought in thoughts:
            if not thought.is_evaluated:
                # In a real implementation, you'd evaluate each thought
                # For demo purposes, we'll assign random-ish scores based on content length and creativity indicators
                creativity_indicators = ['çªç„¶', 'æ„å¤–', 'ç¥ç§˜', 'å¥‡å¦™', 'æƒŠè®¶', 'æ¢¦å¢ƒ', 'å¹»æƒ³', 'é­”æ³•']
                base_score = 2.5
                
                # Bonus for creativity indicators
                for indicator in creativity_indicators:
                    if indicator in thought.content:
                        base_score += 0.3
                
                # Bonus for length (more developed thoughts)
                if len(thought.content) > 100:
                    base_score += 0.5
                
                thought.score = min(5.0, base_score)
                thought.is_evaluated = True
            
            evaluated_thoughts.append(thought)
        
        # Sort by score and return top k
        evaluated_thoughts.sort(key=lambda x: x.score, reverse=True)
        return evaluated_thoughts[:k]
    
    def tree_of_thought_search(self, prompt: str) -> ThoughtState:
        """Main ToT search algorithm"""
        print("ğŸŒ³ å¼€å§‹æ ‘çŠ¶æ€ç»´é“¾æœç´¢...")
        
        # Initialize root
        root = ThoughtState("", 0)
        current_level = [root]
        
        for depth in range(self.max_depth):
            print(f"ğŸ“Š å¤„ç†æ·±åº¦ {depth + 1}/{self.max_depth}")
            next_level = []
            
            for state in current_level:
                # Generate thoughts from current state
                current_content = self.get_path_content(state)
                thoughts = self.generate_thoughts(prompt, current_content, depth)
                
                # Create thought states
                thought_states = []
                for thought in thoughts:
                    new_content = current_content + "\n" + thought if current_content else thought
                    thought_state = ThoughtState(new_content, depth + 1, state)
                    state.add_child(thought_state)
                    thought_states.append(thought_state)
                
                # Select best thoughts
                best_thoughts = self.select_best_thoughts(thought_states, k=2)
                next_level.extend(best_thoughts)
            
            current_level = next_level
            
            if not current_level:
                break
        
        # Return the best final thought
        if current_level:
            best_final = max(current_level, key=lambda x: x.score)
            print(f"âœ… æœ€ä½³è·¯å¾„å¾—åˆ†: {best_final.score:.2f}")
            return best_final
        else:
            return root
    
    def get_path_content(self, state: ThoughtState) -> str:
        """Get the full content path from root to current state"""
        if state.parent is None:
            return state.content
        else:
            parent_content = self.get_path_content(state.parent)
            if parent_content:
                return parent_content + "\n" + state.content
            else:
                return state.content

class ChainOfThought:
    """Traditional Chain of Thought implementation for comparison"""
    
    def __init__(self, api_key: str, base_url: str = None):
        openai.api_key = api_key
        if base_url:
            openai.api_base = base_url
    
    def generate_cot_response(self, prompt: str) -> str:
        """Generate response using traditional chain of thought"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œä¸“å®¶ã€‚è¯·åŸºäºç»™å®šçš„æç¤ºè¿›è¡Œåˆ›æ„å†™ä½œã€‚
ä½¿ç”¨ä¼ ç»Ÿçš„æ€ç»´é“¾æ–¹æ³•ï¼š
1. åˆ†ææç¤ºè¦æ±‚
2. æ„æ€åŸºæœ¬æƒ…èŠ‚
3. é€æ­¥å±•å¼€æ•…äº‹
4. å®Œå–„ç»†èŠ‚æè¿°

è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„åˆ›æ„æ–‡æœ¬ã€‚"""
        
        user_prompt = f"è¯·åŸºäºä»¥ä¸‹æç¤ºè¿›è¡Œåˆ›æ„å†™ä½œï¼š{prompt}"
        
        try:
            response = openai.ChatCompletion.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"ç”ŸæˆCoTå“åº”æ—¶å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚"

class TextEvaluator:
    """Evaluates and compares generated texts"""
    
    def __init__(self, api_key: str, base_url: str = None):
        openai.api_key = api_key
        if base_url:
            openai.api_base = base_url
    
    def evaluate_text(self, prompt: str, text: str, method: str) -> Dict[str, Any]:
        """Evaluate a single text"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ›æ„å†™ä½œè¯„ä¼°ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°åˆ›æ„å†™ä½œä½œå“ï¼š

è¯„ä¼°ç»´åº¦ï¼š
1. åˆ›æ„æ€§ (0-5åˆ†): æƒ³æ³•çš„æ–°é¢–æ€§å’Œç‹¬ç‰¹æ€§
2. è¿è´¯æ€§ (0-5åˆ†): é€»è¾‘ç»“æ„å’Œå™äº‹æµç•…åº¦  
3. æ–‡å­¦ä»·å€¼ (0-5åˆ†): è¯­è¨€è¡¨è¾¾å’Œè‰ºæœ¯ä»·å€¼
4. æƒ…æ„Ÿå…±é¸£ (0-5åˆ†): èƒ½å¦å¼•èµ·è¯»è€…æƒ…æ„Ÿååº”
5. å®Œæ•´æ€§ (0-5åˆ†): æ•…äº‹çš„å®Œæ•´åº¦å’Œç»“æ„æ€§

è¯·ä¸ºæ¯ä¸ªç»´åº¦æ‰“åˆ†ï¼Œå¹¶ç»™å‡ºæ€»åˆ†(0-25åˆ†)å’Œè¯¦ç»†è¯„ä»·ã€‚

è¾“å‡ºæ ¼å¼ï¼š
åˆ›æ„æ€§: Xåˆ†
è¿è´¯æ€§: Xåˆ†  
æ–‡å­¦ä»·å€¼: Xåˆ†
æƒ…æ„Ÿå…±é¸£: Xåˆ†
å®Œæ•´æ€§: Xåˆ†
æ€»åˆ†: Xåˆ†
è¯„ä»·: [è¯¦ç»†è¯„ä»·]"""
        
        user_prompt = f"""
åŸå§‹æç¤º: {prompt}
ç”Ÿæˆæ–¹æ³•: {method}
å¾…è¯„ä¼°æ–‡æœ¬:
{text}

è¯·å¯¹è¿™ä¸ªåˆ›æ„å†™ä½œä½œå“è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚
"""
        
        try:
            response = openai.ChatCompletion.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=500
            )
            
            content = response.choices[0].message.content
            
            # Parse the evaluation
            evaluation = self.parse_evaluation(content)
            evaluation['method'] = method
            evaluation['raw_response'] = content
            
            return evaluation
            
        except Exception as e:
            print(f"è¯„ä¼°æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return {
                'creativity': 3.0,
                'coherence': 3.0,
                'literary_value': 3.0,
                'emotional_resonance': 3.0,
                'completeness': 3.0,
                'total_score': 15.0,
                'evaluation': 'è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯',
                'method': method,
                'raw_response': ''
            }
    
    def parse_evaluation(self, content: str) -> Dict[str, Any]:
        """Parse evaluation response into structured data"""
        lines = content.split('\n')
        evaluation = {
            'creativity': 3.0,
            'coherence': 3.0,
            'literary_value': 3.0,
            'emotional_resonance': 3.0,
            'completeness': 3.0,
            'total_score': 15.0,
            'evaluation': ''
        }
        
        evaluation_text = []
        
        for line in lines:
            line = line.strip()
            if 'åˆ›æ„æ€§:' in line or 'creativity:' in line.lower():
                try:
                    score = float(line.split(':')[1].strip().replace('åˆ†', ''))
                    evaluation['creativity'] = score
                except:
                    pass
            elif 'è¿è´¯æ€§:' in line or 'coherence:' in line.lower():
                try:
                    score = float(line.split(':')[1].strip().replace('åˆ†', ''))
                    evaluation['coherence'] = score
                except:
                    pass
            elif 'æ–‡å­¦ä»·å€¼:' in line or 'literary:' in line.lower():
                try:
                    score = float(line.split(':')[1].strip().replace('åˆ†', ''))
                    evaluation['literary_value'] = score
                except:
                    pass
            elif 'æƒ…æ„Ÿå…±é¸£:' in line or 'emotional:' in line.lower():
                try:
                    score = float(line.split(':')[1].strip().replace('åˆ†', ''))
                    evaluation['emotional_resonance'] = score
                except:
                    pass
            elif 'å®Œæ•´æ€§:' in line or 'completeness:' in line.lower():
                try:
                    score = float(line.split(':')[1].strip().replace('åˆ†', ''))
                    evaluation['completeness'] = score
                except:
                    pass
            elif 'æ€»åˆ†:' in line or 'total:' in line.lower():
                try:
                    score = float(line.split(':')[1].strip().replace('åˆ†', ''))
                    evaluation['total_score'] = score
                except:
                    pass
            elif 'è¯„ä»·:' in line or 'evaluation:' in line.lower():
                evaluation_text.append(line.split(':', 1)[1].strip())
            elif line and not any(keyword in line for keyword in ['åˆ›æ„æ€§', 'è¿è´¯æ€§', 'æ–‡å­¦ä»·å€¼', 'æƒ…æ„Ÿå…±é¸£', 'å®Œæ•´æ€§', 'æ€»åˆ†']):
                evaluation_text.append(line)
        
        evaluation['evaluation'] = '\n'.join(evaluation_text).strip()
        
        return evaluation
    
    def compare_methods(self, prompt: str, cot_text: str, tot_text: str) -> Dict[str, Any]:
        """Compare CoT and ToT results"""
        print("ğŸ“Š è¯„ä¼°ä¼ ç»Ÿæ€ç»´é“¾ç»“æœ...")
        cot_eval = self.evaluate_text(prompt, cot_text, "ä¼ ç»Ÿæ€ç»´é“¾ (CoT)")
        
        print("ğŸ“Š è¯„ä¼°æ ‘çŠ¶æ€ç»´é“¾ç»“æœ...")
        tot_eval = self.evaluate_text(prompt, tot_text, "æ ‘çŠ¶æ€ç»´é“¾ (ToT)")
        
        # Calculate improvements
        improvements = {}
        for key in ['creativity', 'coherence', 'literary_value', 'emotional_resonance', 'completeness', 'total_score']:
            improvements[key] = tot_eval[key] - cot_eval[key]
        
        return {
            'cot_evaluation': cot_eval,
            'tot_evaluation': tot_eval,
            'improvements': improvements,
            'tot_better': tot_eval['total_score'] > cot_eval['total_score']
        }